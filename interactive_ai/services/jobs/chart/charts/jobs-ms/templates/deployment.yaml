apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ .Release.Namespace }}-{{ .Chart.Name }}
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "jobs-ms.labels" . | nindent 4 }}
spec:
  selector:
    matchLabels:
      {{- include "jobs-ms.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      annotations:
        sidecar.opa-istio.io/inject: enabled
      labels:
        {{- include "jobs-ms.selectorLabels" . | nindent 8 }}
        opa_envoy_filter: enabled
    spec:
      serviceAccountName: {{ .Release.Namespace }}-{{ .Chart.Name }}
      initContainers:
        - name: volume-permissions
          image: "{{ .Values.global.busybox.registry }}/{{ if .Values.global.busybox.repository }}{{ .Values.global.busybox.repository }}/{{ end }}{{ .Values.global.busybox.name }}"
          imagePullPolicy: {{ .Values.imagePullPolicy }}
          command:
            - /bin/sh
          args:
            - -c
            - |
              find {{ .Values.audit_logs_mount_path }} -type d -exec chown -v {{ .Values.securityContext.runAsUser }} {} +
          volumeMounts:
            - name: data-storage
              mountPath: "/{{ .Values.audit_logs_mount_path }}"
              subPath: {{ .Values.audit_logs_mount_path }}
              readOnly: false
          resources:
            {{ toYaml .Values.initResources | nindent 12 }}
          securityContext:
            {{ toYaml .Values.volumeSecurityContext | nindent 12 }}
        # [mTLS STRICT] The kubectl-wait init container is used to wait for the init job that is related to this specific component.
        # This is a workaround to address the issue that arises when using Istio mTLS strict mode and init containers
        # that do not have the Istio proxy sidecar
        - name: "kubectl-wait"
          image: "{{ .Values.global.kubectl.registry }}/{{ if .Values.global.kubectl.repository }}{{ .Values.global.kubectl.repository }}/{{ end }}{{ .Values.global.kubectl.name }}"
          command: [ "/bin/bash", "-c" ]
          args:
            - >-
              kubectl wait jobs
              --timeout=1200s 
              --for=condition=complete 
              --namespace {{ .Release.Namespace }}
              init-job-{{ .Chart.Name }}
          securityContext:
            {{ toYaml .Values.securityContext | nindent 12 }}
          resources:
            {{- toYaml .Values.initResources | nindent 12 }}
      containers:
        - name: &containerName {{ .Chart.Name }}
          resources:
            {{ toYaml .Values.resources | nindent 12 }}
          image: "{{ .Values.global.registry_address }}/{{ .Values.global.docker_namespace }}/{{ .Values.image }}:{{ .Values.global.tag | default .Chart.AppVersion }}"
          imagePullPolicy: {{ .Values.imagePullPolicy }}
          securityContext:
            {{ toYaml .Values.securityContext | nindent 12 }}
          ports:
            - name: http
              containerPort: {{ .Values.service.ports.http }}
              protocol: TCP
            - name: grpc
              containerPort: {{ .Values.service.ports.grpc }}
              protocol: TCP
          livenessProbe:
            tcpSocket:
              port: {{ .Values.service.ports.grpc }}
            periodSeconds: 2
            initialDelaySeconds: 2
            timeoutSeconds: 2
            failureThreshold: 20
          readinessProbe:
            tcpSocket:
              port: {{ .Values.service.ports.grpc }}
            periodSeconds: 2
            initialDelaySeconds: 2
            timeoutSeconds: 2
            failureThreshold: 20
          env:
            - name: CREDITS_SERVICE
              value: credit-system.impt:5556
            - name: DATABASE_ADDRESS
              value: mongodb://{{ .Release.Namespace }}-mongodb:27017/
            {{- if .Values.global.enable_mongodb_credentials }}
            - name: DATABASE_USERNAME
              valueFrom:
                secretKeyRef:
                  name: {{ .Release.Namespace }}-mongodb
                  key: {{ .Chart.Name }}-mongodb-username
            - name: DATABASE_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: {{ .Release.Namespace }}-mongodb
                  key: {{ .Chart.Name }}-mongodb-password
            {{- end }}
            - name: SPICEDB_LOG_PATH
              value: {{ .Values.spicedb_log_file_path }}
            - name: SPICEDB_ADDRESS
              value: {{ .Release.Namespace }}-spice-db:50051
            - name: SPICEDB_TOKEN
              valueFrom:
                secretKeyRef:
                  name: {{ include "spice-db.secretName" . }}
                  key: SPICEDB_GRPC_PRESHARED_KEY
            - name: SPICEDB_CREDENTIALS
              value: "token_and_ca"
            - name: SPICEDB_SSL_CERTIFICATES_DIR
              value: "/etc/tls-secrets"
            - name: ENABLE_TRACING
              value: "true"
            - name: ENABLE_METRICS
              value: "true"
            - name: OTEL_SERVICE_NAME
              value: jobs-microservice
            - name: OTLP_TRACES_RECEIVER
              value: "{{ .Release.Namespace }}-opentelemetry-collector.{{ .Release.Namespace }}:4317"
            - name: OTLP_METRICS_RECEIVER
              value: "{{ .Release.Namespace }}-opentelemetry-collector.{{ .Release.Namespace }}:4317"
            - name: OTLP_TRACES_PROTOCOL
              value: grpc
            - name: K8S_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: K8S_POD_UID
              valueFrom:
                fieldRef:
                  fieldPath: metadata.uid
            - name: K8S_CONTAINER_NAME
              value: *containerName
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.instance.id=$(K8S_POD_NAME),k8s.pod.uid=$(K8S_POD_UID),k8s.container.name=$(K8S_CONTAINER_NAME)
            - name: MONGODB_CREDENTIALS_PROVIDER
              valueFrom:
                configMapKeyRef:
                  name: {{ .Release.Namespace }}-configuration
                  key: mongodb_credentials_provider
            {{- if .Values.global.enable_object_storage }}
            - name: S3_CREDENTIALS_PROVIDER
              valueFrom:
                configMapKeyRef:
                  name: {{ .Release.Namespace }}-configuration
                  key: s3_credentials_provider
            - name: "{{ .Chart.Name | replace "-" "_" | upper }}_S3_SECRET_KEY"
              valueFrom:
                secretKeyRef:
                  name: "{{ .Release.Namespace }}-seaweed-fs"
                  key: "jobs_ms_secret_key"
            - name: "{{ .Chart.Name | replace "-" "_" | upper }}_S3_ACCESS_KEY"
              valueFrom:
                secretKeyRef:
                  name: "{{ .Release.Namespace }}-seaweed-fs"
                  key: "jobs_ms_access_key"
            {{- end }}
          envFrom:
          - configMapRef:
              name: {{ .Release.Namespace }}-feature-flags
          volumeMounts:
            - mountPath: {{ .Values.global.logging_config_dir }}
              name: config
              readOnly: true
            - mountPath: "/{{ .Values.audit_logs_mount_path }}"
              name: data-storage
              subPath: {{ .Values.audit_logs_mount_path }}
            - name: tls-secrets
              mountPath: "/etc/tls-secrets"
              readOnly: true
            - name: temp
              mountPath: /tmp
      volumes:
        - name: config
          configMap:
            name: {{ .Release.Namespace }}-logging-config
        {{- if .Values.global.storage_volume_claim_name_jobs }}
        - name: data-storage
          persistentVolumeClaim:
            claimName: {{ .Values.global.storage_volume_claim_name_jobs }}
        {{- else }}
        - name: data-storage
          emptyDir: {}
        {{- end }}
        - name: tls-secrets
          secret:
            secretName: {{ include "spice-db.tlsSecretName" . }}
            items:
              - key: ca.crt
                path: ca.crt
        - name: temp
          emptyDir: {}
